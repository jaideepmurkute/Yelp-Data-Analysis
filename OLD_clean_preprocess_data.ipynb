{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': 'C:\\\\Users\\\\Vitthal\\\\Desktop\\\\projects\\\\yelp_data', 'data_db_storage_dir': 'C:\\\\Users\\\\Vitthal\\\\Desktop\\\\projects\\\\yelp_data\\\\db_storage', 'data_db_name': 'yelp_data', 'data_db_access_uname': 'db_admin_1', 'data_db_access_pwd': 'pass1234', 'create_db_if_not_exists': True}\n"
     ]
    }
   ],
   "source": [
    "# config_ref = CFG()\n",
    "# config = config_ref.get_config()\n",
    "config = {\n",
    "            'data_dir': 'C:\\\\Users\\\\Vitthal\\\\Desktop\\\\projects\\\\yelp_data',\n",
    "            \n",
    "            'data_db_storage_dir': 'C:\\\\Users\\\\Vitthal\\\\Desktop\\\\projects\\\\yelp_data\\\\db_storage',\n",
    "            'data_db_name': 'yelp_data',\n",
    "            'data_db_access_uname': 'db_admin_1', \n",
    "            'data_db_access_pwd': 'pass1234',\n",
    "            'create_db_if_not_exists': True, # for data_db\n",
    "        }\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file(config, file_name=None, verbose=False):\n",
    "    assert file_name is not None\n",
    "\n",
    "    filepath = os.path.join(config['data_dir'], file_name+'.parquet')\n",
    "\n",
    "    if verbose: print(f\"Reading file: {filepath}\")\n",
    "    df = pq.read_table(filepath).to_pandas()\n",
    "    if verbose: print(\"df.shape: \", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_inf_rows(df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "def filter_data(config, df, file_name=None, dropna=False, dropinf=False, verbose=False):\n",
    "    \n",
    "    if verbose: print(\"Before filtering shape: \", df.shape)\n",
    "\n",
    "    # Filter out rows with NaN values\n",
    "    if dropna:\n",
    "        if verbose: print(\"Before dropping NaNs shape:\", df.shape)\n",
    "        df.dropna(inplace=True)\n",
    "        if verbose: print(\"After dropping NaNs shape:\", df.shape)\n",
    "\n",
    "    # Filter out rows with inf values\n",
    "    if dropinf:\n",
    "        if verbose: print(\"Before dropping Infs shape:\", df.shape)\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        if verbose: print(\"After dropping Infs shape:\", df.shape)\n",
    "\n",
    "    # Filter out ir-relevant data for current analysis\n",
    "    assert file_name is not None\n",
    "    if file_name == 'business':\n",
    "        if verbose: print(\"Before filterin out non-restaurant data shape:\", df.shape)\n",
    "        df = df[df['categories'].str.lower().str.contains('restaurants')]\n",
    "        if verbose: print(\"After filterin out non-restaurant data shape:\", df.shape)\n",
    "    \n",
    "    if verbose: print(\"After filtering shape: \", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_outliers(df, cols, mode='drop', threshold=3, verbose=False):\n",
    "    if verbose: print(\"Before outlier handling shape: \", df.shape)\n",
    "    \n",
    "    if mode == 'drop':\n",
    "        for col in cols:\n",
    "            z_scores = (df[col] - df[col].mean()) / df[col].std()\n",
    "            df = df[z_scores.abs() < threshold]\n",
    "    elif mode == 'clip':\n",
    "        for col in cols:\n",
    "            lower_bound = df[col].mean() - threshold * df[col].std()\n",
    "            upper_bound = df[col].mean() + threshold * df[col].std()\n",
    "            df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "    \n",
    "    if verbose: print(\"After outlier handling shape: \", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_data(config, df, date_cols=None, verbose=False):\n",
    "    # Function to clean and pre-process the pandas dataframe for further data analysis\n",
    "    # call helper function for each of the following steps\n",
    "\n",
    "    # Remove duplicates rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # If the date columns exist; and convert to the datetime format\n",
    "    if date_cols is None:\n",
    "        # infer date columns based on the names\n",
    "        date_cols = [col for col in df.columns if col.lower().contains('date')]\n",
    "    if len(date_cols) > 0:\n",
    "        for col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # create columns type descriptors - int_cols, float_cols, bool_cols, id_cols, numeric_cols, date_cols etc.\n",
    "    if id_cols is None:\n",
    "        id_cols = [col for col in df.columns if col.lower().contains('id')]\n",
    "    \n",
    "    int_cols = [col for col in df.columns if 'int' in str(df.dtype)]\n",
    "    float_cols = [col for col in df.columns if 'int' in str(df.dtype)]\n",
    "    nume_cols = int_cols + float_cols\n",
    "    non_nume_cols = [col for col in df.columns if col not in nume_cols]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"int_cols: \", int_cols)\n",
    "        print(\"float_cols: \", float_cols)\n",
    "        print(\"nume_cols: \", nume_cols)\n",
    "        print(\"non_nume_cols: \", non_nume_cols)\n",
    "        \n",
    "    # create outlier detection and handling function for the float cols and int cols that are not id cols.\n",
    "    df = handle_outliers(df, nume_cols, mode='drop', threshold=3)\n",
    "    \n",
    "\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: C:\\Users\\Vitthal\\Desktop\\projects\\yelp_data\\business.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:  (150346, 14)\n",
      "Before filtering shape:  (150346, 14)\n",
      "Before dropping NaNs shape: (150346, 14)\n",
      "After dropping NaNs shape: (117618, 14)\n",
      "Before dropping Infs shape: (117618, 14)\n",
      "After dropping Infs shape: (117618, 14)\n",
      "Before filterin out non-restaurant data shape: (117618, 14)\n",
      "After filterin out non-restaurant data shape: (44676, 14)\n",
      "After filtering shape:  (44676, 14)\n"
     ]
    }
   ],
   "source": [
    "# files: 'business', 'tip', 'user', 'checkin', 'review'\n",
    "file_name = 'business'\n",
    "df = read_data_file(config, file_name='business', verbose=True)\n",
    "df = filter_data(config, df, file_name, dropna=True, dropinf=True, verbose=True)\n",
    "df = clean_data(config, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['categories'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_trading_env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
